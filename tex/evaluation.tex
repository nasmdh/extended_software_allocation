\section{Evaluation}\label{sec_evaluation}
In this section, we evaluate our proposed hybrid PSO algorithms for the allocation of software applications on heterogenous computing units, which conform to the system model presented in Section \ref{sec_system}. The algorithms are evaluated against different specifications of automotive software applications and execution platforms with regard to effectiveness, stabilitity and scalability. The software-application specifications consist of the number of software components $c$, runnables $r$, tasks $t$ and cause-effect chains $g$.  The specifications are synthesized from the automotive benchmark proposed by Kramel et al.~\cite{Kramer2015RealFree}. The benchmark indicates a strong correlation between runnables and cause-effect chains in terms of timing and activation patterns. It shows the timing specifications of runnables and their shares in an engine management system. Moreover, it shows the activation patterns of cause-effect chains, the runnables per activation and their shares in the system. The engine management system is one of the most complex automotive systems in the vehicular electical/electronic execution platform. 

\paragraph{Software Applications Benchmark} Based on our experience in the automotive industry, the benchmark results  are extrapolated to characterize different classes of automotive software applications specifications, that is by varying the parameters related to the software components, runnables, and cause-effect chains. The different classes of specifications range from Spec-I to Spec-V as shown in Table~\ref{tbl_appsspec}. The specification classes are useful to evaluate and discusse the effectiveness and scalability of the different optimization algorithms. The first specification class Spec-I encompases small software applications with number of components less than 10, runnables less than 50, tasks 30, cause-effect chains less than 30. The Spec-I and Spec-II classes represent medium and large software applications, and the last specification class introduced to strech the performance analysis. Note: the classification is superficial and maynot be realistic and could also be different in different domains.
\begin{table}
\centering\small
\begin{tabular}{@{}lllll@{}}
\toprule
Parameter  		& Spec.-I  & Spec.-II & Spec.-III & Spec.-IV\\
\midrule
Components $c$		& $\leq 10$	& $\leq 15$ 	&$\leq 20$ & $\leq 80$\\ 
Runnables $r$		& $\leq 50$	& $\leq 100$ 	& $\leq 500$&$\leq 1000$\\
Tasks $t$ 			& $\leq 30$ & $\leq 60$ 	& $\leq 80$&$\leq 100$\\
Cause-effect chains $g$ & $\leq$ 30 & $\leq$ 40 & $\leq 60$&$\leq100$\\ \midrule
Activation-pattern	& \multicolumn{4}{c}{$\{2,3,4\}$}\\ \midrule
share of activation-patterns	& \multicolumn{4}{c}{$\{0.7, 0.2, 0.1\}$}\\
\bottomrule
\end{tabular}
\caption{Specification of the Applications for Evaluation.}
\label{tbl_app_ranges}
\end{table}

\paragraph{Execution Platform Specifications}
Likewise, the specifications for an execution platform consist of the processor speed, power specifications and failure rates of computing units, and we assume the range of values to these parameters as shown in Table~\ref{tbl_execpla}.
\begin{table}
	\small
	\parbox{.4\linewidth}{
		\centering
		\begin{tabular}{@{}ll@{}}
			&\\&\\
			\toprule
			Parameter  			& Range\\ 
			\midrule
			EE $ms$					 	& $100-1000$\\
			RL 						& 0.99999999\\
			CL 						& \{A,B,C,D\}\\
			\bottomrule
		\end{tabular}
		\caption{Ranges of Values for Applications Requirements.}
		\label{tbl_app_ranges}
	}
~
	\parbox{.5\linewidth}{
		\centering\raggedbottom
		\begin{tabular}{@{}ll@{}}
			\toprule
			Parameter  		& Range\\ 
			\midrule
			Nodes $n_N$							& $4-20$\\
			$P_{min},P_{max}$ (Watt)	& $1-10$\\
			$\lambda_n$ ($h^{-1}$) 	& $10^{-4}-10^{-2}$\\
			$\lambda_B$ ($h^{-1}$) 	& $10^{-4}-10^{-2}$\\
			$Hz$ (MHz)			 	& $80-800$\\
			\bottomrule
		\end{tabular}
		\caption{Ranges of Values for Execution Platforms.}
		\label{tbl_execpla}
	}
\end{table}
%\begin{table}
%	\small
%\begin{subtable}[b]{0.5\textwidth}
%		\begin{tabular}{@{}ll@{}}
%	\toprule
%	Parameter  		& Range\\ 
%	\midrule
%	Nodes $n_N$							& $4-10$\\
%	$P_{min},P_{max}$ (Watt)	& $1-10$\\
%	$\lambda_n$ ($h^{-1}$) 	& $10^{-4}-10^{-2}$\\
%	$\lambda_B$ ($h^{-1}$) 	& $10^{-4}-10^{-2}$\\
%	$Hz$ (MHz)			 	& $80-800$\\
%	\bottomrule
%	\end{tabular}
%		\caption{Ranges of Values for Execution Platforms.}
%		\label{tbl_execpla}
%	\end{subtable}
%	~
%	\begin{subtable}[b]{0.4\textwidth}
%		\begin{tabular}{@{}ll@{}}
%		\toprule
%		Parameter  			& Range\\ 
%		\midrule
%		EE					 	& 100$n_\Gamma$\\
%		RL 						& 0.99999999\\
%		CL 						& \{A,B,C,D\}\\
%		\bottomrule
%	\end{tabular}
%		\caption{Ranges of Values for Applications Requirements..}
%		\label{tbl_app_ranges}
%\end{subtable}
%\caption{Samples Specifications.}
%\label{tbl_samplesspecs}
%\end{table}

\paragraph{Applications Requirements Specifications } Table~\ref{tbl_reqs}  shows the range of values used in our experiment to specify the requirements of software applications, that include the end-to-end timing requirements $EE$ of chains, the reliability requirement $RL$ and the criticality level $CL$. The end-to-end requiremens are assumed as a function of length of the chain $n_\Gamma$, that is the longer the chain, the higher the number. The reliability range of safety-critical automotive application is usually given in higher degree of 9, for operation of over a long period of time, which implies almost no failure during the specified duration.

\paragraph{Evaluation Setup} The evaluation is conducted on a MacBook Pro laptop comptuer, with hardware specifications as follows: Intel Core i7 processor type, 2.6.GHz processor speed, 6 Cores , 9 MB L3 cache, and 16 GB memory.

\subsection{Result}
We conduted two experiments: i) the first experiment is designed to compare the performance  such as converge time, computation time, optimality (or solutions quality), and stability of solutions of the meta-heuristic algorithms used in this paper, ii) the second experiment is designed to evaluate the overhead of increasing replication on the optimization especially on the computation of cause-effect chains, and also to evaluate the effect of the approximation algorithms proposed in Subsection x to reduce the overheadd and maybe trade-off with optimality of solutions.
\begin{table}[h]
	\centering\small
	\begin{tabular}{@{}lp{0.8\linewidth}@{}}
		\toprule
		Algorithm & Parameters Settings\\ 
		\midrule
		PSO	& Particle Swarm Optimization: learning factors $c_1=c_2=1.49445\in [0,4]$,  number of particles 40, iterations 5000	\\
		DE	& Differential Evolution: crossover $CR=0.5\in[0,1]$, scale factor $F=0.7\in[0,2]$  \\
		PF& Penality Function:  $\beta_1$=,  $\beta_2=$, $ \beta_3=$\\
		\bottomrule
	\end{tabular}
	\caption{Parameters Settings of the Metaheuristic Optimization. .}
	\label{tbl_para}
\end{table}

\paragraph{Experiment 1} According to the specifications of the range discussed, we synthesized six optimization problems as shown in Table~\ref{tbl_samples}. The problems emulate the software allocation safety-critical distributed automotive applications on a CAN network of heterogenous computing nodes. The problems are identified by handlers of type $\langle c_ig_jn_i\rangle$ to improve readability, where the $c,g,n$ variables indicate respectively the number of components, cause-effect chains and computing nodes. The \pb{6}{10}{4}  and \pb{8}{20}{6} problems conform to Spec-I and denote a small (or light) optimization problem, the \pb{10}{20}{8} problems is based on Spec-II and denote a medium size problem, the \pb{20}{30}{10}, \pb{50}{40}{20} and \pb{80}{60}{20} are based on Spec-III and denote large size problem. The optimization problems are executed each 30$\times$ using our ILP method proposed in \cite{Mahmud5222} and the meta-heuristic algorithms presented in Section~\ref{sec_solution}. The optimization parameters such as the penality function coefficient and the meta-heuristic parameters control the metaheuristics optimization, and their settings are shown in  Table~\ref{tbl_para}. The settings are obtained from literature as best practices of using the algorithms, as well as from our experimentaion of the algoriths with the problems at hand. Subsequently, we recorded the computation time, fitness values, power-consumption delivered by each algorithm.
\begin{table}
\centering\small
	\begin{tabular}{@{}lllll@{}}
		\toprule
		Problem id & Components $c$ & Runnables $r$ & Chains $g$& Units $n$\\ 
		\midrule
		\pb{6}{10}{4} 		& 6 	& 60 & 10 & 4\\
		\pb{8}{20}{6}  		& 8     &80& 20 & 6 \\
		\pb{10}{20}{8}  	& 10   &100& 20 & 8 \\
		\pb{20}{30}{10}   & 20 	 & 200&30& 10 \\ 
		\pb{50}{40}{20}  & 50 	 &500& 60 & 20 \\
		\pb{80}{60}{20}  & 80	&800& 60 & 20 \\
		\bottomrule
	\end{tabular}
\caption{Specifications of the Optimization Problems, Sampled from Table~\ref{tbl_app_ranges} and Table~\ref{tbl_exec_ranges}, and Used in Experiment 1 and 2. }
\label{tbl_samples}
\end{table}

%\begin{table}
%	\small
%\begin{subtable}[b]{0.5\textwidth}
%		\begin{tabular}{@{}lllll@{}}
%			\toprule
%			Identifier & EE & RL & F& \#Units (n)\\ 
%			\midrule
%			\pb{6}{10}{4} 		& 6 	& 60 & 10 & 4\\
%			\pb{8}{20}{6}  		& 8     &80& 20 & 6 \\
%			\pb{10}{20}{8}  	& 10   &100& 20 & 8 \\
%			\pb{20}{30}{10}   & 20 	 & 200&30& 10 \\ 
%			\pb{50}{40}{20}  & 50 	 &500& 60 & 20 \\
%			\pb{80}{60}{20}  & 80	&800& 60 & 20 \\
%			\bottomrule
%		\end{tabular}
%		\caption{Experiment 1.}
%		\label{tbl_samples}
%	\end{subtable}
%	~
%	\begin{subtable}[b]{0.4\textwidth}
%			\begin{tabular}{@{}lll@{}}
%			\toprule
%			Identifier & Chains& Replication (n)\\ 
%			\midrule
%			$g_{30}r_{2}$ 	&30	& 2 	\\
%			$g_{30}r_{2}$ 	&30	& 3     \\
%			$g_{30}r_{2}$ 	&60	& 2    \\
%			$g_{30}r_{2}$ 	 &60& 3 	 \\ 
%			\bottomrule
%		\end{tabular}
%			\caption{Experiment 2.}
%			\label{tbl_samples}
%\end{subtable}
%\caption{Samples Specifications.}
%\label{tbl_samplesspecs}
%\end{table}

Table~\ref{tbl_fitness_allocationtime_ilp_plus_metaheuristic} shows a summary of the evaluation results from executing Experiment~1 such as the average and standard deviation of the computation times and fitness values, as well as the quality of solutions. The latter is determined by comparing the power-consumption outcomes delivered from each algorithms agains the optimal or best solutions found (or benchmarks), which are indicated by the \textbf{boldface} type. It simplly indicates how optimal or good the solution is as compared to the benchmark. In the first three optimization problems, the ILP is the benchmark since it returned optimal solutions. Similarly, the SHPSO is the benchmark in the problems \pb{20}{30}{10} and \pb{50}{40}{20}, and SHPSO is the benchmark in the last probem \pb{80}{60}{20}.
\input{tex/evaluation_result_computationtime.tex}

\paragraph{Experiment 2} Usually the replication exerts heavy computation over the calculation of the cause-effect delays due its combinatorial nature. The approximation technique, which is presented in Subsection~\ref{sub_repl_delay}, optimizes the calculation of the cause-effec chain delays in the presenece of replication. We executed the optimization problems \pb{50}{40}{20} and \pb{80}{60}{20} with 2 and 3 degrees of replication, and also with and without the approximation technique applied according to the specification in Table~\ref{tbl_samples}. The degree of replication indicates the multiplicity of each component in the software applications.
\begin{table}
	\centering\small
	\begin{tabular}{@{}llll@{}}
	\toprule
	Identifier & Chain $g$ & Replication $d$ & Problem id.\\ 
	\midrule
	$g_{30}d_{2}$ 	&30	& 2 &	\pb{50}{40}{20}\\
	$g_{30}d_{2}$ 	&30	& 3  &   \pb{50}{40}{20} \\
	$g_{30}d_{2}$ 	&60	& 2 &   \pb{80}{60}{20}\\
	$g_{30}d_{2}$ 	 &60& 3 &	 \pb{80}{60}{20}\\ 
	\bottomrule
\end{tabular}
\caption{Specifications of Samples, tobe Used in Experiment 2.}
\label{tbl_samples}
\end{table}

\subsection{Analysis}
In this subsection, we analyze the results from experiement 1 and 2, respectively.
\subsubsection{Analysis of Experiment 1}
We analyze the results over three metrices: computation and convergence time, solution quality and stability, respectively.

\paragraph{Solution Quality} In the $1^{st}$ sample \pb{6}{10}{4}, the ILP, DE, LPSO, HCPSO, SHPSO returned the optimal power consumption, which is 227KW, but DEPSO and PSO returned near optimal solutions with $>99\%$ quality measures. In the $2^{nd}$ sample  \pb{8}{20}{6}, similar results are obtained from ILP, HCPSO and SHPSO, which are optimal, but this time, in contrast, DE, LPSO and DEPSO performed worse by less than 1\% but better than PSO by ~2\%.  In the $3^{rd}$ sample \pb{12}{20}{8}, only ILP returned the optimal solution, followed by DEPSO, LPSO, HCPSO, SHPSO with near optimal solutions with $>99\%$ quality measures, and rest performed worse. In the last three samples \pb{20}{30}{10}, \pb{50}{40}{20} and \pb{80}{60}{20} , ILP did not return solutions due to extremly large computation time, hence terminated manually. However, the hybrid algorithms based on hill-climbing such as HCPSO and SHCPSO performed well, followed by DEPSO in the samples \pb{20}{30}{10} and \pb{80}{60}{20} . However, HCPSO failed to returned solutions in the largest sample \pb{80}{60}{20} but its stochastic verion SHCPSO did.
\begin{figure}[h!]
\centering
\includegraphics[width=1\linewidth]{img/power_consumption.pdf}
\caption{(Near) Optimal Power Consumption of the Different Software Allocation Problems.}
\label{fig_powerconsumption_ilp_metaheuristic}\vspace{-0.4cm}
\end{figure}

\paragraph{Convergence Time} In the case of metaheuristics, the convergence time refers to the amount of time taken by the algorithm to return solutions before the steady state where new fitness values are observed. In this evalution, it is calculated over a maximum of 5000 iterations (or generations) only for the duration before steady period, which is bounded by 5 minutes. Note: the steady time, where no fitness values change within the maximum iterations, is not considered in the converge time.  Figure \ref{fig_allocationtime_ilp_metaheuristic} summarizes the computation time of the algorithms for the samples listed in Table~\ref{tbl_fitness_allocationtime_ilp_plus_metaheuristic}. For the samples the ILP method returned solutions, the computation times are usually larger than the rest, which are in milliseconds for the $1^{st}$ sample and in seconds for the $2^{st}$  and $3^{rd}$.  The the meta-heuristic algorithms, the convergence time is in milliseconds for the first four samples, and is in seconds for the rest. However, the computation times of the meta-heuristic algorithms, which are not shown in the table usually took less than 50 minutes for the larest sample.
\begin{figure}[h!]
\centering
\includegraphics[width=1\linewidth]{img/time_summary.pdf}
\caption{Computation Time of the Various Algorithms for Solving Different Instances of the Software Allocation Problem.}
\label{fig_allocationtime_ilp_metaheuristic}\vspace{-0.4cm}
\end{figure}
%\input{tex/evaluation_result_table.tex}
\paragraph{Solutions Stability} the PSO, DE are characterized by random search which enables exploration of higher dimenstional problems possible. However, somestime this creates instability in the solutions, that is for the same problem, it is possible to observe different performance, e.g., fitness values, computation time, etc. The stability of the solutions depend on the nature of the algorithms as well as the problems at hand. Therefore, it is crucial to evaluate the stability of the meta-heuristic algorithms used in this work. One way measuring the stability is using standar deviation, and Figure x and Figure y show the deviation of each algorithms for the (near) optimal power consumption of the different samples.

In general, with regard to quality of the solutions, the hybrid PSO with hill-climbing are more stable in the first three samples, but also DE and LPSO in $1^{st}$ sample, as compared to PSO and DEPSO. However, as the problem size increases to $1^{st},2^{nd}, 3^{rd}$,  the hybrid PSO with hill-climbing performed worse and PSO and others improved. With regard to convergence time, the stability usually decreased, that is with uniformity for the PSO, DE, HCPSO and SHPSO, however, for the rest it is not uniform.

\subsubsection{Analysis of Experiment 2}
Table~\ref{fig_chainsreplicationimprovements} shows results of executing experiment 2, which shows improvements of the computation time by applying the approximation algorithm in stead of the exact approach. In the case of the approximation, the delays are exaustively calculated in the presence of replication. However, the quality of the solutions are degraded as expected due to the approximation. Specifically, the result shown $61\%-81\%$ computation time improvement over the exac method while facing quality degradation only for samples $g_{30}d_{2}$ and  $g_{30}d_{2}$. The improvements are in seconds, which implies for a single usage (or run) of the meta-heuristic optimization algorithms, it is not significant. However, considering practical systems design process, which requires several iterations, the commulative effect of the algorithms can negatively impact the responsivess to engineers. Thus, the improvements can be in trade-off with optimality of the solutions.
\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{img/chains_replication_improvements}
	\caption{Effect of Approximate Algorithm over Delay Calculations with Replication.}
	\label{fig_chainsreplicationimprovements}
\end{figure}

\section{Discussion}
