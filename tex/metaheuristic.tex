\section{Metaheuristic Approach}
Although the proposed ILP approach provides exact solutions, that is an AUTOSAR architecture with minimum power consumption, simultaneously satisfying timing and reliability requirements for relatively small and medium software applications, it is shown in the previous section that the approach does not scale well for large applications. Thus, in this section, we propose an approximation approach based on several metaheuristic techniques to address the scalability challenge. Metaheuristic methods are ideal for high dimensional and complex problems, that is problems difficult or practically impossible to solve by exact methods, e.g., linear programming. They have improved over the last decades with respect to effectiveness, efficiency, and ease of use (that is, few user parameters for manipulating the metaheuristic algorithms). Metaheuristic techniques do not guarantee optimal solutions, nevertheless, the returned solutions could be good enough (or acceptable) in the eyes of the system designer, which means although the power consumption of the system is not optimal, the solution can be deemed acceptable, that is as long as the the constraints are fulfilled. In the opposite case, where the constraints could not be fulfilled, the algorithms can be run several times until the desired result is found, or the design can be relaxed by weakening the timing and reliability constraints of the system.

Metaheuristic techniques perform differently for different problem types, size, and complexity. In this section, we show application of different metaheuristic techniques that employ swarm intelligence and evolutionary approaches in finding the near (optimal) solutions. Specifically, we apply the Particle Swarm Intelligent (PSO), Differential Evolution techniques primarily, and further hybrid PSO with DE and Hill-climbing for improved performance.PSO has been applied to solve a wide range of problems, including a task allocation problem \cite{yin2007task}, and DE is shown to scale well for problems with high dimensions. In fact, PSO and DE are used together for improved performance in several optimization problems, likewise, PSO is used with local search techniques such as Hill climbing to intensify the search. Finally, we evaluate the different metaheuristic methods based on solution quality (optimality and degree of constraint violations) and computation time for various problem sizes.

\subsection{Particle Swarm Optimization}
% What is PSO
PSO is a population-based technique proposed by Eberhart and Kennedy in 1995 to study social behavior, as inspired by natural swarm intelligence observed from the flocking of birds and schooling of fishes \cite{Kennedy1995ParticleOptimization}. Since then, it extended in order to address various metaheuristic optimization challenges, such as intensification, diversification, convergence analysis, local optima, parameter tuning, computation time, etc. It is successfully applied on several complex real-world problems, e.g., diagnosis and classification of diseases, efficient engineering designs, tuning control design parameters, scheduling problems, etc \cite{Poli2008AnApplications}. 

In PSO, the population (or swarm) is a collection of particles, organized according to a certain population topology \cite{Liu2016TopologyOptimization}. A particle has a position $\textbf{x}$ and a velocity $\textbf{v}$, which denote, respectively, the current location and direction of the the particle, and the current momentum of the particle. It is a memory-based technique, that is it remembers the best performance of every particle as well as the best performance of the swarm $\textbf{z}$ in order to plan the next move of the particles, where $y,z$ are position vectors and have the same dimension as $x$. The velocity of a particle is the resultant vector of its current velocity and the particles attraction vectors $(\textbf{y}-\textbf{x}), (\textbf{z}-\textbf{x})$, respectively, known as \textit{cognitive} and \textit{social} components of the  particle's velocity formula, as shown in Equation \ref{eqn_pso_velocity}. Thus, the next position of a particle is the resultant of its current position and its next velocity as shown in Equation \ref{eqn_pso_position}.
\begin{align}
    \label{eqn_pso_velocity}
    \textbf{v} &\leftarrow  \omega\textbf{v} + c_1Rand()\circ(\textbf{z}-\textbf{x}) + c_2Rand()\circ(\textbf{z}-\textbf{x})\\
    \label{eqn_pso_position}
    \textbf{x} &\leftarrow \textbf{x} + \textbf{v}
\end{align}
where $\omega$ is the weight of the velocity, also known as \textit{inertia coefficient}, and controls the convergence of the algorithm, $c_1, c_2$ are acceleration coefficients and controls the weight of attraction towards the cognitive and social components, respectively, $Rand()\in U(0,1)$ is a random function, along the acceleration coefficients, is element-wise multiplied with the components to improve diversity of the search by introducing stochastic behavior.

Although PSO was originally proposed for continuous problem, it is applied to discrete problems successfully. In the latter case, the solutions are represented by 0-1 integer variables \cite{KennedyAAlgorithm} or integer programming by approximation to the nearest integer values \cite{Clerc2000DiscreteProblem}, which is the the representation employed for our problem. Accordingly, after the new position (or candidate solution) is determined, following Equations \ref{eqn_pso_velocity} and \ref{eqn_pso_position}, the solution is discretized by rounding off the its elements to the nearest integer values, that is $\textbf{x}\leftarrow [\textbf{x}]$.

\subsection{Solution Representation of the Software Allocation Problem}
The software allocation problem is a type of job shop scheduling, as such it is discrete, that is its solution takes on discrete values $\textbf{x}\in \{1,…,L\}^N$. The solution is represented by a matrix of size $N\times K$ as show in Figure \ref{fig_pso_solution_representation}, where $x_{ik}=j\in \{1,…,L\}$ denotes allocation of the software component replica $c_{ij}$ on the computation node $m_j$, that is $c_{ik}\mapsto m_j$.
\begin{equation}
\label{fig_pso_solution_representation}
\textbf{x}=
\begin{bmatrix} 
x_{11} & x_{12} & \dots & x_{1K}\\
x_{21} & x_{22} & \dots & x_{2K}\\
\vdots & \vdots & \ddots & \vdots\\
x_{I1} & x_{I2} & \cdots & x_{IK}
\end{bmatrix}
\end{equation}

In contrast to the \textit{0-1} representation, the integer-linear representation uses much lower number of variables, that is $N*K(L-1)$, e.g., for a software allocation problem with $N=10,L=8,K=2$, 140 variables are saved. Of course the possible values in the former representation is two whereas in the latter representation, it is $L$, which is usually higher and results larger solution space. Nevertheless, the integer-linear representation is compact and computationally more efficient.

\subsection{Defining Fitness Function}
% Define the fitness function
Since a metaheuristic method functions over the meta of a problem, the quality of candidate solutions is evaluated based on their fitness to meet the problem's objective. A solution that delivers lower power consumption and violates less constraints is indicated by a lower fitness value. The fitness function $f(\textbf{x})$ combines the original objective function $P(\textbf{x})$ and the constraints $Timing(\textbf{x}),Reliability(\textbf{x})$ in order to compute real-valued numbers that indicate quality of the candidate solutions.

Consequently, the original constrained optimization problem is transformed into unconstrained optimization problem, by extending the objective function $P(\textbf{x})$ with the constrains, represented by a \textit{penalty function} $\Phi(\textbf{x})$. The function returns 0 if no constrains are violated otherwise returns a positive number, essentially to penalize the candidate solution by increasing its fitness (for our minimization problem), thus discriminating the solution. The function is a combination of $\beta\sum{g_i(\textbf{x})}$ and $\gamma h(\textbf{x})$ functions, respectively computes the timing violations and a software application reliability violation, and each function is weighted to indicate the size of the penalty separately. Moreover, the penalty function $\Phi({\textbf{x}})$ is weighted to indicate the size of penalty that imposed on the combined violations of timing and reliability. \textbf{How to compute the parameters [Hamid]}
\begin{align}
\label{}
    \min_{\textbf{x}\in X}\;\;& f(\textbf{x})=P(\textbf{x}) + \alpha \Phi(\textbf{x})\\
    \label{eqn_penalityfunc}\Phi(\textbf{x}) &= \sum\phi_i(\textbf{x})
\end{align}

% Show the representation of the a solution
% Demonstrated it on the example
\begin{algorithm}
\caption{PSO Algorithm}\label{alg_pso}
\begin{algorithmic}[1]
\Require n
\Ensure Near (Optimal) Solution
\State $x_{sb}\leftarrow$ getWorstPosition()
\State $Particles\leftarrow$ createParticles($n$)
\State initParticles($Particles$)
\While{$!stoppingCritera$}
    % Calculate personal best, swarm best positions
    \State \Comment{Calculate personal best and swarm best positions of the particles}
    \ForAll{$p \in Particles$}
        \State $particle \leftarrow$  getPosition($p$)
        \State $x_{pb} \leftarrow$  getPosition($p$) 
        \If{$fitness(x)\leq fitness(x_{pb})$} \Comment{Personal best position}
            \State $x_{pb}\leftarrow x$
            \If{$fitness(x)\leq fitness(x_{sb})$} \Comment{Swarm best position}
                \State $x_{sb}\leftarrow x$
            \EndIf 
        \EndIf 
    \EndFor
    % Calculate next positions of the particles
    \State \Comment{Calculate next positions of the particles}
	\ForAll{$p \in Particles$}
        \State $v\leftarrow v+c1*r1*(x_{pb}-x)+c2*r2*(x_{sb}-x)$ 
        \State $x\leftarrow$ getPosition($p$)$ + v$
        %\State setParticlePosition($p,x$)
    \EndFor
\EndWhile
\end{algorithmic}
\end{algorithm}\vspace{-0.2cm}

\subsection{Differential Evolution}

\subsection{Hybrid Particle Swarm Optimization}
