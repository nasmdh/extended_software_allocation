\section{Related Work}\label{sec_RW}
%There are a large number of research works analyzing the reliability of distributed systems with a focus on hardware faults (computing and communication equipment errors). In other words, they assume that the software part of the system is perfect and the source of unreliability of the system is hardware faults ~\cite{dai2003study}\cite{zhang2015maximizing}\cite{faragardi2013analytical}.

In a heterogeneous distributed systems where computing nodes and communications links could have various hazard rates, a reliability-aware allocation of tasks to nodes, and using the links with the lowest hazard rates can noticeably improve the system reliability~\cite{shatz1992task}\cite{kartik1997task}\cite{yin2007task}\cite{zhang2015maximizing}. 
%This approach has been used in multiple works to improve the system reliability with no extra hardware/software cost~\cite{yin2007task}\cite{zhang2015maximizing}. 
Interleaving real-time constraints into the problem adds more complexity to reliability-aware task allocation in distributed systems~\cite{faragardi2013optimal}. As opposed to \cite{Wozniak2013AnArchitectures}\cite{Saidi2015AnArchitectures}, we assume that software applications are multi-rate, i.e., the applications execute with different period (or activation patterns). Multi-rate applications increase the difficulty of software allocation due to the several timed paths traversing from the source to the sink in cause-effect chains.

Although improving reliability of the system using a reliability-aware task allocation does not impose extra hardware/software cost,  in reliability-based design approach, redundancy (or replication) of software or hardware components is frequently applied to improve reliability. In such systems not only optimal allocation of software components (or replicas) should be taken into account but also the cardinality of the replicas should be limited for improved efficiency while meeting the desired reliability requirement. The integration of these two approaches (i.e., reliability-aware task allocation and application redundancy) is a promising technique to deal with high criticality of the system to fulfill the required reliability of the system. For example, \cite{assayad2004bi} proposes a heuristic algorithm to maximize reliability of a distributed system using task replication while at the same time minimizing the makespan of the given task set as the other objective of the optimization problem. Furthermore, in systems with replication, it uses the Minimal Cut Sets method, which is an approximate algorithm, to calculate reliability of a system. In contrast, we apply an exact method based on State Enumeration, which is applicable to the problem size assumed in this work.

%Although improving reliability of the system using a reliability-aware task allocation does not impose extra hardware/software cost, it may not be enough for critical systems such as automotive and automation applications. In such systems not only optimal allocation of software components to nodes should be taken into account but also application redundancy as one of the well-known techniques to improve the reliability of distributed systems must be adopted. The integration of these two approaches (i.e., reliability-aware task allocation and application redundancy) is a promising technique to deal with high criticality of the system to fulfill the required reliability of the system. For example, \cite{assayad2004bi} proposes a heuristic algorithm to maximize reliability of a distributed system using task replication while at the same time minimizing the makespan of the given task set as the other objective of the optimization problem. 

In our problem, power consumption is the other criterion of the optimization problem. There are a lot of research works focusing on improving power consumption in real-time distributed systems. The research work~\cite{bambagini2016energy} shows a survey of different methods on energy-aware scheduling for real-time systems. The studies in the survey can be categorized into two major groups: i) using Dynamic Voltage Scaling (DVS) (e.g., ~\cite{devadas2012interplay},wang2015dynamic), and ii) using task consolidation to minimize the number of used computing and communication elements~\cite{faragardi2013towards}, which is the approach in our work.

In the context of automotive systems, there are few works considering the reliability of a distributed system subject to real-time requirements of the automotive applications~\cite{islam2006dependability}\cite{kim2011autosar}. There are also other works discussing the allocation of software components onto nodes of a distributed real-time systems that consider other types of constraints other than reliability, for example, i) ~\cite{wang2004component} which considers computation, communication and memory resources, and ii) ~\cite{vsvogor2014extended} which proposes a genetic algorithm for a multi-criteria allocation of software components onto heterogeneous nodes including CPUs, GPUs, and FPGAs. Our approach also considers a hetrogeneous platform, i.e., nodes with different power consumption, failure-rate, and processor speed. In this work, we consider only the processor time; however, it can easily be extended to take into account different types of memory consumption that the software applications require.
